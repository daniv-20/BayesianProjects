---
title: "Project 2"
author: "Sam Albertson, Suz Angermeier, & Dani Vaithilingam"
date: "3/10/2023"
output: 
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# libraries
library(dplyr)
```

# Safety Monitoring Rule

## Objective of the Safety Monitoring Rule
The goal of the safety monitoring rule is to set a trigger for determining when the rate of severe adverse events is too high. A maximum acceptable rate is pre-specified, and if we are confident that the probability exceeds this level, the study is discontinued. 

## Parameter to Estimate and Hypothesis
The parameter we try to estimate for the safety monitoring rule is the proability $\theta$ that a patient will have an adverse event of Grade 3 (severe) or higher. We define our maximum clinically acceptable risk level as $\theta_{mcid}$ = 0.05; our safety monitoring rule is triggered if there is a greater than 80% chance that $\theta > \theta_{mcid}$. 

## Statistical Model

The beta-binomial model is a functional family of a prior (beta distribution) and likelihood (binomial distribution) function. These are multiplied together at a range of values of $\theta$ to generate our posterior distribution, from which we can estimate the probability that $\theta > \theta_{mcid}$

### Prior
The prior distribution represents our knowledge of the adverse event rate before conducting the study. We use a $Beta(1,1)$ prior, which contains no information about the parameter, to represent our lack of informaton about the event rate.

### Likelihood
The likelihood function represents the chance of observing the number of events seen in the trial, given a proposed risk level. We define this mathematically using a $Binomial(N_{events}, N_{total}, \theta)$ distribution. This provides an empirical estimate of the event rate parameter.


### Posterior Distribution
We define the posterior distribution as the product of the prior and the likelihood of our data:

$P[Y|X] \sim P[Y] * L[Y | X]$

### Critical Boundary

```{r safety_table}
f_post <- function(x){
  pct <- signif(1 - pbeta(0.05, x + 1, 50 - x + 1), 3)
  return(paste0(pct, "%"))
}

df_post <- data.frame(Events = 0:50) %>%
  mutate(`Posterior Probability` = f_post(Events))
```


\newpage 

# Operating Characteristics of the Efficacy Analysis

## Objective
Describe in your own words what the objective of the efficacy analysis is.

## Parameter to Estimate and Hypothesis
Describe the parameter to be estimated in the efficacy analysis, the minimum clinically relevant value for the parameter, and the hypothesis to be tested. What are the success criteria for the efficacy analysis?

## Statistical Model
Show the statistical model for the analysis, including prior, likelihood and posterior distribution. State these mathematically and in plain English as they relate to the objectives of the study. Note, there are 3 priors discussed in the protocol: one used for the primary analysis and two used for sensitivity analyses, the "optimistic" and "pessimisic" priors. Discuss why these priors are labeled as optimistic or pessimistic and what impact you think they might have on the posterior distribution. 

## Definition of Power and Type I Error in the Context of the Efficacy Analysis
Any stochastic rule for success or failure could lead to an incorrect conclusion. How are the possibilities for drawing an incorrect conclusion represented in the Bayesian framework for this trial? Explain this plan English. 

## Design of Your Program to Evaluate the Operating Characteristics of the Efficacy Analysis

### Inputs 
Describe the input that goes into the program.

### Outputs
Describe what the program creates as a final result.

### Algorithm
Describe how the program operates to produce output from the input. You can use words or draw a diagram, or both.

## Program Code

Show your program code here.

## Comparison of Program Output to the Results in the Study Protocol
Create two tables--one for Type I error and one for Power--that compare your results with those shown in the protocol so you can verify that your program produces the correct results.
